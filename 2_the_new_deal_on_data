Essential Elements of the New Deal on Data in the Context of Institutional Controls [Arek]

To realize the 
promise and prospects of big data and 
avoid itâ€™s security and confidentiality perils, 
a balanced set of institutional controls are needed. 
These institutional controls 
must
support and reflect 
greater user control over personal data and 
also large scale interoperability 
for data sharing 
between and among institutions. 
Core capabilities of these controls 
include responsive 
rules-based systems governance and 
fine grained authorizations for 
distributed rights management.



From the institution standpoint it is easier to facilitate data exchange: institution acting as a matchmaking service, user authorization fully 
expressed by the user 


this requires identity: who owns the data, who decides, who accesses...

some data must be authorized to be used; some identity attributes must be authorized

the ownership is not about changing, it is about control

at the very least, the knowledge that data exists


---

Our lives are embedded within institutions. We are citizens of the countries and cities, receive services from telecom operators, we search for things to buy in the online stores. 
All those activities we perform, generate data and those breadcrumbs of our lives are important part of the Big Data promise. The data that is not curated by us, but is collected as it is, reflecting our lives.

Today, all these data that we generate in the context of institutions, is closed in silos. The trace of our mobility is owned by our mobile provider, our music tastes are stored and used by music services. For this data to be useful for society, it must be opened, must be used much more than it is now.
If the access to the data for creating the value, either for the user or for the society, is very limited, it doesn't really matter how big the data is. The value is not in the sheer data existence, but availability.
Opening the data from multiple silos at once is even more challenging. Living under multiple jurisdictions, accessing the multi-faced data about one person may be prohibitively difficult. Silos are hard to crack open. And such data, no just Big but Deep, covering multiple facets of person's life may be invaluable for research.

Recently, we have showed how challenging but also, at the same time, perfectly possible is opening such data. In the Data For Development (D4D) challenge, the telecom operator Orange opened the access to a large dataset of telecom records from the Ivory Coast. Organized as a challenge, teams of researchers came up with life-changing insights. The privacy of the people was protected not only by the technical means, such as removal of the Personally Identifiable Information, but also by the legal means, with the researchers signing the agreement that they will not use the data for evil. As we have seen in several cases, such as Netflix Prize privacy disaster, real anonymization is extremely hard, it is very easy to fingerprint people in the dataset. Some of the weight of the privacy must rest on the legal solutions.

Opening the data from the silos, by publishing static datasets is important, but is only the first step. We can do even more important things, when the data is available in real time and can become a part of a nervous system of a society. Epidemics and traffic congestions can be monitored and prevented in real time, underpferoming students can be helped, people with health risks can be treated before the disease happens.  
The same data can be used for stalking, burglarizing my home, and as a reason to charge me more for an insurance.

In the Unique in the Crowd project, we have shown that, even though human beings are highly predictable \cite{song2010limits}, we are also very unique. Having access to one dataset, it is easy to fingerprint someone based on just a few datapoints, and use this fingerprint to discover their true identity. The higher the resolution of the data, the better the data, the easier it gets.

The question of privacy in this context effectively becomes the question of control. Who can release the data of my movements? To whom? How much and how often? It is the institution that collects this data. It is data about me. It does not belong to me, I may not even be aware that it exists. I cannot decide upon it, I cannot check it out. I cannot delete it. And very few can use it, even if I wanted them to.

It does not have to be like that. Within existing legal frameworks, it is possible to change the vantage point of the data ownership and put the user, the entity about whom the data is, in control. It may be the copy of the data living in the great silo, being given to the user. The user becoming the owner of their copy of the data, or where possible the original. Owner in the old Common Law sense: the right to use, transfer, and remove. 
An example of such mechanism is Blue Button initiative, where the patients can get the copy of their health records. Once the copy is with them, they can do with it as they wish: give it to someone, make it public, do research on it, destroy.

The user can accumulate data about herself from multiple places. Healthcare records, mobility patterns, favorite movies, all this information belongs to the user and can be accessed based on this user authorization.
This changes the type of data that can be obtained. Rather than gaining access to the movements of millions of people from a telcom operator, one can potentially gain access to a smaller number but much richer datasets describing the users from the mobility, health, shopping etc. perspectives. 

===


The first, operational challenge of moving towards the end-user data ownership on a large scale, is to make the personal data used by anyone. The entire ecosystem operates currently on feudal principles: Facebook owns the data generated by you and about you, and will provide the access to it to the 3rd parties that you might or might have not authorized. It is reasonably easy to download all your data from Facebook. It is reasonably easy to put it on Dropbox or even create me-api, becoming a self-hosted API to one's own personal data. The challenge is to have any client to talk to this API and provide service. Everyone is ready to talk to Facebook about your data. Virtually no-one is ready to talk to you. The Internet has done a reasonably better job with identity: you can deploy your own OpenID server fairly easily, and many services will allow you to sign in. We should be heading in the same direction with data.

The way the user grants the authorizations to the data he owns, is not a trivial matter. Think who you have authorized to know what city you are in today. The Yes you have clicked many times, gave access to your location to multiple services. Every tweet, every geo-tagged picture, every checkin provides your location not only to the primary service you are using, but also to all the applications that you have authorized to access this data. Take a look at your applications page on Twitter, Facebook, Google...

If we are talking about increasing the amount of data the user controls, and increasing the granularity of the control, it would be meaningless if this control cannot be exercised in an informed way. The EULA-catastrophe, where you may be just as well giving up your soul when signing up, will not bring us closer to the New Deal on Data. In the end, it must the be user that makes the informed decision about who will get the access to the data and for what purpose. Make the authorization interface too complex and you will fail. Make it too simple, and you will also fail. Write it in legal complex language, and you cannot claim that the user expresses Informed consent. Start asking the user about authorization every 5 minutes, and you will only teach her to press Yes every time. 

In addition to the data ownership, we need a better way for the end-user to control what happens with it. Will user realize that clicking the Yes button will provide a service with a second-resolution location data? And what can be inferred from such data, regarding alcohol abuse (we see you a lot in a liquor store), driving habits, not enough exercise etc. This gap between the interface and the effect, can pretty much render the data ownership meaningless. There is a need for Living Informed Consent, where the interface for the user to grant the authorizations is created to give the user understanding of the consequences of the authorizations she is granting. It will never be perfect, but aligning this user's understanding with the reality is the goal of the Living Informed Consent initiative. 

We envision several ways the Living Informed Consent can improve user's understanding of the authorization she is granting. The underlaying principle is that the status of the authorizations expressed via the interface is the contract. By pressing the buttons, the user initiates technical actions (for example creation of OAuth2 tokens), but also changes her business and legal relation with the service. Such single screen, with a timestamped log constitutes a history of the consent. It may differ in granularity (do not collect my data this evening), and some actions may or may not be permitted. Still, at any point in time, the user is in certain relation with the service, on the Business, Legal, and Technical plains. 
The consent only makes sense when the user understands what she is consenting to. Otherwise, why even bother asking. Part of the gestalt is to provide concise authorizations description written in plain English. They will not always be trivial and may sometime turn into paragraphs of text, still the goal should be to provide a description easily understandable for the target audience.
Additionally, the goal should be not only to ask for the access to data, but also include the purpose of the access. Location is a type of data. Using location to provide personalized music and using location to increase my insurance for careless driving are two very different authorizations. Currently, the widely used OAuth2 framework does not support the notion of purpose, focusing only on the data being accessed.
Dimensionality reduction....
Feedback on data usage... 






@article{song2010limits,
  title={Limits of predictability in human mobility},
  author={Song, Chaoming and Qu, Zehui and Blumm, Nicholas and Barab{\'a}si, Albert-L{\'a}szl{\'o}},
  journal={Science},
  volume={327},
  number={5968},
  pages={1018--1021},
  year={2010},
  publisher={American Association for the Advancement of Science}
}